{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9efc012-e1c0-4c0e-8933-94b15b637643",
   "metadata": {},
   "source": [
    "The task here is to do a part of data preprocessing before connecting it to the **PowerBI** environment.\n",
    "\n",
    "Basically, I'll do next things:\n",
    "- Create **Kaggle losses** .csv file (will be demonstated in one dashboard).\n",
    "- Create .csv file, which contains all product families (will be used to comfortly establish relationships).\n",
    "- Modify train dataset by removing observations when stores didn't start operating (otherwise it will be pretty rough to do inside Power Query).\n",
    "- Modify holiday dataset (make terms more understandable and preserve only 1 (most important) holiday per day (to maintain one-to-many relationships).\n",
    "- Resample and interpolate oil dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fd5c886-cb82-46c4-8259-2d3c6e289a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9576e7b9-0c7f-422a-97c7-3306f68a0956",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_dict = {\n",
    "    'Holt-Winters': 0.43131,\n",
    "    'Ridge': 0.45105,\n",
    "    'Random Forest': 0.42014,\n",
    "    'k-NN': 0.43540,\n",
    "    'XGBoost': 0.43196,\n",
    "    'LightGBM': 0.42780,\n",
    "    'Ensemble': 0.39999\n",
    "}\n",
    "\n",
    "model_losses = pd.Series(losses_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0bf7cf2-599d-477a-a738-0517cc3c0b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_losses.to_csv('preprocessed_datasets/model_losses.csv', index_label='Model', header=['RMSLE Loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "612a6966-f3b4-44b4-a3d5-0288453bdc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('initial_datasets/train.csv', index_col=0)\n",
    "starting_day = pd.read_csv('preprocessed_datasets/starting_day.csv', index_col=0).squeeze()\n",
    "\n",
    "unique_sf = train.groupby(['store_nbr', 'family']).count().index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df1cd202-733b-440d-959f-e1e0e7dd0f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(train['family'].unique()).to_csv('preprocessed_datasets/families.csv', header=['Family'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ccc4865-6eb4-4acc-8f0d-8558d770aa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s, f in unique_sf:\n",
    "    temp = train[(train['store_nbr'] == s) & (train['family'] == f)]\n",
    "    indexes_to_drop = temp.iloc[:starting_day[s], :].index\n",
    "\n",
    "    train = train.drop(index=indexes_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1adb68a4-b121-467f-8686-81f9c73d465b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_ds_jan1 = train[(train['date'].dt.month == 1) & (train['date'].dt.day == 1)].groupby(['date', 'store_nbr']).sales.sum()\n",
    "\n",
    "grouped_ds_jan1 = grouped_ds_jan1[grouped_ds_jan1 == 0].reset_index()\n",
    "\n",
    "to_delete = pd.merge(train.reset_index(), grouped_ds_jan1, on=['date', 'store_nbr'], how='inner')\n",
    "train = train.drop(to_delete.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "881a7913-eb3f-4302-9ce8-058b9331d1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('preprocessed_datasets/train_modified_start.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d9ba250-bcce-424b-a3fa-9743ae1bb8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays = pd.read_csv('initial_datasets/holidays_events.csv', index_col=0, parse_dates=True)\n",
    "holidays['priority'] = holidays['locale'].map({'National': 1, 'Regional': 2, 'Local': 3})\n",
    "holidays = holidays.sort_values(['priority'])\n",
    "holidays = holidays[~holidays.index.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0ba2333-664b-4d83-aec2-14cc84a45bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays.loc[holidays[holidays['transferred'] == True].index, 'type'] = 'Moved'\n",
    "holidays['type'] = holidays['type'].map(lambda x: 'Sat/Sun Working Day' if x == 'Work Day' else x)\n",
    "holidays = holidays.drop(columns=['transferred', 'priority'])\n",
    "\n",
    "min_date = '2013-01-01'\n",
    "max_date = '2017-08-31'\n",
    "\n",
    "complete_dates = pd.date_range(start=min_date, end=max_date)\n",
    "holidays = holidays.reindex(complete_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84051d3d-fc57-46de-9874-7f9cbfe0e1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays = holidays.fillna('Working Day')\n",
    "\n",
    "holidays.to_csv('preprocessed_datasets/holidays_events_modified.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53af90b1-919d-44e9-bb69-6bd5109f8b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "oil = pd.read_csv('initial_datasets/oil.csv', index_col=0, parse_dates=True)\n",
    "oil = oil.resample('1D').asfreq().interpolate('linear').reset_index()\n",
    "oil.to_csv('preprocessed_datasets/oil_modified.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
